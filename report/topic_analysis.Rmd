---
title: "North Korea and Trump"
author: "Michelle, Chris, Tom, Albert and Yu-Xi"
date: "13 August, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(RSQLite)
library(data.table)
library(topicmodels)
library(tidyverse)
library(tidytext)
library(qdap)
library(tidyr)

# Load Data
input_text <- data.table(read.csv("tweets.csv"))
```

## Data Preparations

We have scraped from Python using the tweeper library any tweets that contains "North Korea".  For LDA analysis, we first clean the data to:

- Remove things like "http", "\\" or symbols like "+" etc
- Convert to ASCII 
- Trimming and replace incomplete sentences etc

```{r data cleaning}
# Data Cleaning
{
  # Text cleaning ---------------------------------------------
  tweet <- sapply(input_text$tweet,as.character)
  tweet <- sapply(tweet, function(x) gsub("@\\s.+\\shttp","http",x))  #Remove @place
  tweet <- sapply(tweet, function(x) gsub("htt.*","",x))
  tweet <- sapply(tweet, function(x) gsub("@\\w+", " ", x))  #Remove @User
  tweet <- sapply(tweet, function(x) gsub("#", " ", x))
  tweet <- sapply(tweet, function(x) gsub("\\!", "\\.", x))
  tweet <- sapply(tweet, function(x) gsub("\\?", "\\.", x))
  tweet <- sapply(tweet, function(row) iconv(row, "latin1", "ASCII", sub=""))
  tweet <- clean(tweet)
  tweet <- tolower(tweet)
  tweet <- replace_number(tweet, remove = TRUE)
  tweet <- scrubber(tweet)
  tweet <- incomplete_replace(tweet)
  tweet <- Trim(tweet)
  tweet <- bracketX(tweet,bracket = "all")
  tweet <- add_incomplete(tweet,silent = TRUE)
  tweet <- comma_spacer(tweet)
  tweet <- unname(tweet)
  
  remove.words <- c("amp", "The", "will", 'You','just', 'meekmouseracist', 
                    'north', 'korea', '...', 'like')
  
  # Word cloud---------------------------------------------------
  TD_matrix <- tweet	%>%
    #	select(tweet) %>%
    as.matrix() %>%
    tm::VectorSource() %>%
    tm::Corpus() %>%
    tm::tm_map(tm::removeWords, tm::stopwords("english")) %>%
    tm::tm_map(tm::removeWords, remove.words) %>%
    tm::TermDocumentMatrix() %>% 
    # tm::removeSparseTerms(sparse = 0.9995) %>%
    as.matrix()
}
```

```{r TDA Analysis}
# LDA function only takes rows as Docs and columns as Terms, transpose 
TD_matrix <- t(TD_matrix)

# remove those with 0 row sums
TD_matrix <- TD_matrix[rowSums(TD_matrix) != 0, ]

ap_lda <- LDA(TD_matrix, k = 3, control = list(seed = 1234))

```

```{r Topical results}
# Exploring 
ap_topics <- tidy(ap_lda, matrix = "beta")
ap_topics

ap_top_terms <- ap_topics %>%
  group_by(topic) %>%
  top_n(10, beta) %>%
  ungroup() %>%
  arrange(topic, -beta)

plot1 <- ap_top_terms %>%
  mutate(term = reorder(term, beta)) %>%
  ggplot(aes(term, beta, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  coord_flip()

```

```{r Plotting}
# plot
plot1
```